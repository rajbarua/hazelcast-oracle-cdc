---
######################
## Prometheus
######################
# Add prometheus helm repo
- name: Add helm repo of Prometheus
  kubernetes.core.helm_repository:
    name: prometheus-community
    repo_url: "https://prometheus-community.github.io/helm-charts"
    force_update: true
  tags:
    - prometheus
    - kafka
# Install Prometheus in monitoring namespace
- name: Install Prometheus
  shell: helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring --create-namespace
  register: command_result
  failed_when: command_result.rc >= 2
  tags:
    - prometheus
    - kafka
######################
## Jeager
######################
# Create namespace observability for Jeager
- name: Create namespace observability for Jeager
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: Namespace
      metadata:
        name: observability
  tags:
    - jeager
######################
## Strimzi
######################
# Add strimzi helm repo
- name: Add helm repo of Strimzi
  kubernetes.core.helm_repository:
    name: strimzi
    repo_url: "https://strimzi.io/charts/"
    force_update: true
  tags:
    - kafka
    - strimzi
# Install Strimzi via helm with custom values
- name: Install Strimzi
  kubernetes.core.helm:
    name: strimzi
    chart_ref: strimzi/strimzi-kafka-operator
    namespace: kafka
    create_namespace: true
    values:
      dashboard:
        enabled: true
        namespace: monitoring
      featureGates: +UseKRaft,+KafkaNodePools,+UnidirectionalTopicOperator
  tags:
    - kafka
    - strimzi
  
# Wait for Strimzi to be ready
- name: Wait for Strimzi to be ready
  shell: "kubectl wait --for=condition=ready pod -l name=strimzi-cluster-operator --timeout=300s -n kafka"
  tags:
    - kafka
    - strimzi
######################
## Kafka
######################    
# Create KafkaNodePool
- name: Create KafkaNodePool
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: kafka.strimzi.io/v1beta2
      kind: KafkaNodePool
      metadata:
        name: dual-role
        namespace: kafka
        labels:
          strimzi.io/cluster: my-cluster
      spec:
        replicas: 2 #3
        roles: 
          - controller
          - broker
        storage:
          type: ephemeral
        template:
          pod:
            affinity:
              podAntiAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchExpressions:
                      - key: strimzi.io/name
                        operator: In
                        values:
                          - my-cluster-kafka
                  topologyKey: kubernetes.io/hostname
  tags:
    - kafka
    - kafka-crd
    - kafka-node-pool
# Create ConfigMap called kafka-metrics
- name: Create ConfigMap called kafka-metrics
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: kafka-metrics
        namespace: kafka
      data:
        kafka-metrics-config.yml: |-
          lowercaseOutputName: true
          rules:
          - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
            name: kafka_server_$1_$2
            type: GAUGE
            labels:
              clientId: "$3"
              topic: "$4"
              partition: "$5"
          - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
            name: kafka_server_$1_$2
            type: GAUGE
            labels:
              clientId: "$3"
              broker: "$4:$5"
          - pattern: kafka.server<type=(.+), cipher=(.+), protocol=(.+), listener=(.+), networkProcessor=(.+)><>connections
            name: kafka_server_$1_connections_tls_info
            type: GAUGE
            labels:
              cipher: "$2"
              protocol: "$3"
              listener: "$4"
              networkProcessor: "$5"
          - pattern: kafka.server<type=(.+), clientSoftwareName=(.+), clientSoftwareVersion=(.+), listener=(.+), networkProcessor=(.+)><>connections
            name: kafka_server_$1_connections_software
            type: GAUGE
            labels:
              clientSoftwareName: "$2"
              clientSoftwareVersion: "$3"
              listener: "$4"
              networkProcessor: "$5"
          - pattern: "kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+):"
            name: kafka_server_$1_$4
            type: GAUGE
            labels:
              listener: "$2"
              networkProcessor: "$3"
          - pattern: kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+)
            name: kafka_server_$1_$4
            type: GAUGE
            labels:
              listener: "$2"
              networkProcessor: "$3"
          - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*><>MeanRate
            name: kafka_$1_$2_$3_percent
            type: GAUGE
          - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*><>Value
            name: kafka_$1_$2_$3_percent
            type: GAUGE
          - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*, (.+)=(.+)><>Value
            name: kafka_$1_$2_$3_percent
            type: GAUGE
            labels:
              "$4": "$5"
          - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*, (.+)=(.+), (.+)=(.+)><>Count
            name: kafka_$1_$2_$3_total
            type: COUNTER
            labels:
              "$4": "$5"
              "$6": "$7"
          - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*, (.+)=(.+)><>Count
            name: kafka_$1_$2_$3_total
            type: COUNTER
            labels:
              "$4": "$5"
          - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*><>Count
            name: kafka_$1_$2_$3_total
            type: COUNTER
          - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Value
            name: kafka_$1_$2_$3
            type: GAUGE
            labels:
              "$4": "$5"
              "$6": "$7"
          - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>Value
            name: kafka_$1_$2_$3
            type: GAUGE
            labels:
              "$4": "$5"
          - pattern: kafka.(\w+)<type=(.+), name=(.+)><>Value
            name: kafka_$1_$2_$3
            type: GAUGE
          - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Count
            name: kafka_$1_$2_$3_count
            type: COUNTER
            labels:
              "$4": "$5"
              "$6": "$7"
          - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*), (.+)=(.+)><>(\d+)thPercentile
            name: kafka_$1_$2_$3
            type: GAUGE
            labels:
              "$4": "$5"
              "$6": "$7"
              quantile: "0.$8"
          - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>Count
            name: kafka_$1_$2_$3_count
            type: COUNTER
            labels:
              "$4": "$5"
          - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*)><>(\d+)thPercentile
            name: kafka_$1_$2_$3
            type: GAUGE
            labels:
              "$4": "$5"
              quantile: "0.$6"
          - pattern: kafka.(\w+)<type=(.+), name=(.+)><>Count
            name: kafka_$1_$2_$3_count
            type: COUNTER
          - pattern: kafka.(\w+)<type=(.+), name=(.+)><>(\d+)thPercentile
            name: kafka_$1_$2_$3
            type: GAUGE
            labels:
              quantile: "0.$4"
          - pattern: "kafka.server<type=raft-metrics><>(.+-total|.+-max):"
            name: kafka_server_raftmetrics_$1
            type: COUNTER
          - pattern: "kafka.server<type=raft-metrics><>(.+):"
            name: kafka_server_raftmetrics_$1
            type: GAUGE
          - pattern: "kafka.server<type=raft-channel-metrics><>(.+-total|.+-max):"
            name: kafka_server_raftchannelmetrics_$1
            type: COUNTER
          - pattern: "kafka.server<type=raft-channel-metrics><>(.+):"
            name: kafka_server_raftchannelmetrics_$1
            type: GAUGE
          - pattern: "kafka.server<type=broker-metadata-metrics><>(.+):"
            name: kafka_server_brokermetadatametrics_$1
            type: GAUGE
  tags:
    - kafka
    - kafka-crd
# Create Kafka cluster
- name: Create Kafka cluster
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: kafka.strimzi.io/v1beta2
      kind: Kafka
      metadata:
        name: my-cluster
        namespace: kafka
        annotations: # (1)
          strimzi.io/node-pools: enabled
          strimzi.io/kraft: enabled
      spec:
        kafka:
          config:
            offsets.topic.replication.factor: 2 #3
            transaction.state.log.replication.factor: 2 #3
            transaction.state.log.min.isr: 1 #2
            default.replication.factor: 2 #3
            min.insync.replicas: 2
            inter.broker.protocol.version: '3.6'
          storage: # (2)
            type: ephemeral
          listeners:
            - name: plain
              port: 9092
              type: internal
              tls: false
            - name: tls
              port: 9093
              type: internal
              tls: true
          version: 3.6.0
          replicas: 2 #3
          metricsConfig: # (3)
            type: jmxPrometheusExporter
            valueFrom:
              configMapKeyRef:
                name: kafka-metrics
                key: kafka-metrics-config.yml
        entityOperator:
          topicOperator: {}
          userOperator: {}
        cruiseControl: {} # (4)
        # (5)
        zookeeper:
          storage:
            type: ephemeral
          replicas: 2 #3
  tags:
    - kafka
    - kafka-crd
    - kafka-cluster
# Wait for Kafka cluster to be ready. Retry three times on error
- name: Wait for Kafka cluster to be ready
  shell: "kubectl wait --for=condition=ready pod -l strimzi.io/kind=Kafka --timeout=300s -n kafka"
  register: command_result
  until: command_result.rc == 0
  retries: 20
  delay: 10
  tags:
    - kafka
    - kafka-crd
    - kafka-cluster
  

# Create a topic called payments
- name: Create a kafka topic called payments
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: kafka.strimzi.io/v1beta2
      kind: KafkaTopic
      metadata:
        name: payments
        namespace: kafka
        labels:
          strimzi.io/cluster: my-cluster
      spec:
        partitions: 12
        replicas: 2 #3
        config:
          retention.ms: 7200000
  tags:
    - kafka
    - topic

# Create a topic called cdc
- name: Create a kafka topic called payments
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: kafka.strimzi.io/v1beta2
      kind: KafkaTopic
      metadata:
        name: cdc
        namespace: kafka
        labels:
          strimzi.io/cluster: my-cluster
      spec:
        partitions: 12
        replicas: 2 #3
        config:
          retention.ms: 7200000
  tags:
    - kafka
    - topic

# - name: Using kubecrl create a secret called docker-credentials from gcp credentials. Ignore if already exists
#   # https://stackoverflow.com/questions/36283660/creating-image-pull-secret-for-google-container-registry-that-doesnt-expire
#   # https://cloud.google.com/artifact-registry/docs/docker/authentication#json-key not using this
#   shell: "kubectl -n kafka create secret docker-registry docker-credentials --docker-server={{ region }}-docker.pkg.dev --docker-username=_json_key --docker-password=\"$(cat {{ credentials_file }})\" "
#   register: command_result
#   failed_when: 
#     - command_result.rc != 0
#     - "'already exists' not in command_result.stderr"
#   tags:
#     - kafka
#     - kafka-connect

# - name: Create Kafka Connect resource along with debezium image
#   # https://strimzi.io/docs/operators/latest/overview#configuration-points-connect_str
#   # https://debezium.io/documentation/reference/stable/connectors/oracle.html#oracle-deploying-a-connector
#   kubernetes.core.k8s:
#     state: present
#     definition:
#       apiVersion: kafka.strimzi.io/v1beta2
#       kind: KafkaConnect
#       metadata:
#         name: debezium-connect
#         namespace: kafka
#         annotations:
#           strimzi.io/use-connector-resources: "true"
#       spec:
#         bootstrapServers: my-cluster-kafka-bootstrap.kafka.svc:9092
#         config:
#           # https://strimzi.io/docs/operators/latest/overview#configuration-points-connect_str - "Kafka Connect cluster configuration for workers" section
#           group.id: debezium-connect-cluster
#           offset.storage.topic: debezium-connect-offsets
#           config.storage.topic: debezium-connect-configs
#           status.storage.topic: debezium-connect-status
#           key.converter: org.apache.kafka.connect.json.JsonConverter
#           value.converter: org.apache.kafka.connect.json.JsonConverter
#           key.converter.schemas.enable: true
#           value.converter.schemas.enable: true
#           config.storage.replication.factor: 2 #3
#           offset.storage.replication.factor: 2 #3
#           status.storage.replication.factor: 2 #3
#         build:
#           output:
#             type: docker
#             image: "{{ region }}-docker.pkg.dev/{{ project_id }}/{{ repository_id }}/debezium-connect"
#             pushSecret: docker-credentials
#           plugins:
#             # https://strimzi.io/docs/operators/latest/configuring#plugins
#             - name: debezium-plugin
#               artifacts:
#                 - type: tgz
#                   url: https://repo1.maven.org/maven2/io/debezium/debezium-connector-oracle/2.5.1.Final/debezium-connector-oracle-2.5.1.Final-plugin.tar.gz
#                 - type: jar
#                   # use correct version jar
#                   # url: https://repo1.maven.org/maven2/com/oracle/database/jdbc/ojdbc8/21.6.0.0/ojdbc8-21.6.0.0.jar
#                   url: https://repo1.maven.org/maven2/com/oracle/database/jdbc/ojdbc8/23.3.0.23.09/ojdbc8-23.3.0.23.09.jar
#                 - type: jar
#                   # use correct version jar
#                   # url: https://repo1.maven.org/maven2/com/oracle/database/xml/xdb/21.6.0.0/xdb-21.6.0.0.jar
#                   url: https://repo1.maven.org/maven2/com/oracle/database/xml/xdb/23.3.0.23.09/xdb-23.3.0.23.09.jar
#   tags:
#     - kafka
#     - kafka-connect
# - name: Wait for Kafka Connect to be ready. Retry after 30 seconds for 10 times
#   shell: "kubectl wait --for=condition=ready pod -l strimzi.io/kind=KafkaConnect --timeout=300s -n kafka"
#   register: command_result
#   until: command_result.rc == 0
#   retries: 10
#   delay: 30
#   tags:
#     - kafka
#     - kafka-connect

# This bit will be executed by Hazelcast
# - name: Create KafkaConnector so that Oracle connection properties can be set
# # https://strimzi.io/docs/operators/latest/overview#configuration-points-connect_str - KafkaConnector management of connectors
# # https://debezium.io/documentation/reference/stable/connectors/oracle.html#oracle-example-configuration
#   kubernetes.core.k8s:
#     state: present
#     definition:
#       apiVersion: kafka.strimzi.io/v1beta2
#       kind: KafkaConnector
#       metadata:
#         name: debezium-connector
#         namespace: kafka
#         labels:
#           strimzi.io/cluster: debezium-connect
#       spec:
#         class: io.debezium.connector.oracle.OracleConnector
#         tasksMax: 1
#         autoRestart: # (5)
#           enabled: true
#         config:
#           database.hostname: "oracle-db23c-free-oracle-db23c-free.default.svc.cluster.local"
#           database.port: "1521"
#           database.user: "c##dbzuser"
#           database.password: dbz
#           database.dbname: "FREE"
#           topic.prefix : "server1"
#           # table.include.list : "C##DBZUSER.CUSTOMERS"
#           schema.history.internal.kafka.bootstrap.servers: "my-cluster-kafka-bootstrap.kafka.svc:9092"
#           schema.history.internal.kafka.topic: "schema-changes.oracle"
#           database.pdb.name: "FREEPDB1"
#   tags:
#     - kafka
#     - kafka-connect
#     - kafka-connector
